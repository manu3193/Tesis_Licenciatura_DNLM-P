%% ---------------------------------------------------------------------------
%% intro.tex
%%
%% Introduction
%%
%% $Id: intro.tex 1477 2010-07-28 21:34:43Z palvarado $
%% ---------------------------------------------------------------------------

\chapter{Introducción}
\label{chp:intro}

Los algoritmos de procesamiento de im\'agenes son ampliamente utilizados en campos como la medicina, microbiolog\'ia e incluso deportes \cite{Aggarwal2011,	Ekin2003, Fils_BfilCells_2008}. El mejoramiento de las im\'agenes por medio de algoritmos de procesamiento permiten obtener el realce de caracter\'isticas o informaci\'on relevante y la atenuaci\'on de informaci\'on poco importante o no deseada en una imagen. 

Sumado a lo anterior, la eliminaci\'on de ruido en las im\'agenes se considera un problema ampliamente resuelto en la literatura, con una gran gama de t\'ecnicas propuestas \cite{edgpreservefilter}. Se ha demostrado que la presencia de ruido en las im\'agenes reduce el rendimiento de algoritmos de procesamiento de im\'agenes como segmentaci\'on, rastreo de objetos, clasificaci\'on y la extracci\'on de caracter\'isticas \cite{BF2014,IMPROVESEGMENTATIONBF,CONCAPAN2016}. Esto hace que sea necesaria la integraci\'on de algoritmos de eliminaci\'on de ruido con t\'ecnicas de realce de informaci\'on, como etapa de preprocesamiento para mejorar el rendimiento de las etapas posteriores de procesamiento.  

En la literatura se encuentran aplicaciones que requieren el preprocesamiento de los datos, como es el caso del an\'alisis automatizado de videos de actividad celular \cite{saenz2015deceived}. En este trabajo los autores proponen un sistema automatizado de segmentaci\'on y rastreo de c\'elulas, con el objetivo de asistir a investigadores del c\'ancer y campos afines a comprender de una  manera m\'as r\'apida y precisa el comportamiento de grupos de c\'elulas afectadas por la enfermedad \cite{saenz2015deceived}. La primera etapa de el sistema de rastreo de c\'elulas presentado por los autores, corresponde al preprocesamiento de las im\'agenes de entrada. En esta etapa se usa un filtro de promedio ponderado para la eliminaci\'on de ruido, como lo son el filtro bilateral y el filtro Non-Local Means (NLM). Este filtro se integra con un m\'etodo de Unsharp Masking con el objetivo de mejorar los bordes y el contraste en la imagen, como se propone en \cite{calderon2015dewaff}. 

Adem\'as, en \cite{CNN_DNLM} se propone el uso de una etapa de preprocesado para algoritmos de procesamiento de im\'agenes basados en redes convolucionales ya que muestra un impacto positivo en el rendimiento general del modelo. Los algoritmos de preprocesamiento de im\'agenes basados en modelos de redes convolucionales generan extractores de caracter\'isticas a partir de los datos de entrenamiento, a diferencia de los enfoques convencionales de procesamiento de im\'agenes. Lo anterior hace pensar que los modelos basados en redes convolucionales son m\'as robuztos ante la presencia de ruido en im\'agenes. Sin embargo, los resultados obtenidos en \cite{CNN_DNLM} sugieren que los m\'etodos basados en redes convolucionales tambi\'en se ven afectados por el ruido en los datos. Esto hace que sea necesario explorar etapas de preprocesamiento de los datos para eliminar el ruido y adem\'as realzar informaci\'on relevante.

La mejora en el rendimiento de m\'etodos de reconocimiento de patrones basados en im\'agenes, utilizando algoritmos de preprocesamiento efectivos y complejos, generalmente implica en un aumento considerable en cuanto a necesidad de recursos computacionales. Esto hace que sea necesario el desarrollo de algoritmos de preprocesamiento cada vez m\'as eficientes que logren mitigar el aumento en la complejidad computacional en las tareas comunes de procesamiento de im\'agenes. 


El filtro NLM propuesto en \cite{buades2005non} ha demostrado resultados destacables en t\'erminos relaci\'on se\~nal-ruido y poca degradaci\'on o p\'erdida de detalles como bordes, en comparaci\'on con otros filtros como el de mediana y el bilateral \cite{CONCAPAN2016}. Esto es debido a que su enfoque se basa en la similitud entre los vecindarios de los pixeles de la imagen para asignar el peso correspondiente a la contribuci\'on de cada pixel vecino en el ponderamiento del valor del pixel procesado. 

Uno de los principales inconvenientes del filtro NLM es su complejidad computacional: en el peor de los casos, para una imagen de entrada de $N$ pixeles utilizando un tamaño de ventana deslizante de $A\times B = N$ y un tamaño de vecindario de $A\times B = N$, la complejidad computacional est\'a dada por $\mathcal{O}(N^{3})$, tardando hasta $32s$ en el filtrado de una imagen de 1024x1024 pixeles \cite{Zhu2016}. Esto hace que el filtro DNLM sin optimizar sea poco pr\'actico para los investigadores de \'areas como la microbiolog\'ia, ya que frecuentemente necesitan analizar videos de actividad celular compuestos por cientos de miles de im\'agenes, implicando m\'ultiples d\'ias de procesamiento. 

Existen mejoras desarrolladas a partir del algoritmo NLM como la propuesta en \cite{calderon2015dewaff} llamada Deceived Non-Local Means (DNLM). Presenta una combinaci\'on del m\'etodo \textit{Unsharp Mask} (USM) con el filtro NLM por medio del desacoplamiento de la imagen utilizada en el pesado y la imagen usada en el filtrado. Esto permite reducir los artefactos no deseados en las im\'agenes (efecto de anillo) generados por el enfoque convencional, es decir, al aplicar en una primera etapa el m\'etodo USM y posteriormente el filtro NLM \cite{calderon2015dewaff}.  


Una forma de reducir la complejidad computacional del filtro es mediante el uso de optimizaciones o aproximaciones del algoritmo. En este trabajo se incluye el estudio de optimizaciones computacionales exactas del algoritmo y no aproximaciones. Esto es debido a que algunas optimizaciones logran reducir en efecto la complejidad computacional del algoritmo, sin embargo en este trabajo nos interesan las optimizaciones con la misma respuesta que la implementaci\'on original del filtro. 

Sumado al an\'alisis de las optimizaciones algor\'itmicas del filtro DNLM para disminuir su costo computacional, se busca alcanzar el mayor aprovechamiento del \textit{hardware} por medio de la vectorizaci\'on y paralelizaci\'on del algoritmo. Para esto se propone una estrategia de paralelizaci\'on para computaci\'on de alto rendimiento enfocada en la arquitectura Xeon Phi Knigths Landing disponible en las instalaciones del Centro Nacional de Alta Tecnolog\'ia, como parte del cl\'uster de alto rendimiento "Kabr\'e" del Colaboratorio Nacional de Computaci\'on Avanzada (CNCA).

La estrategia de paralelizaci\'on propuesta en este trabajo se enfoca en la paralelizaci\'on del algoritmo a nivel intra-nodo, para el aprovechamiento total de los n\'ucleos de procesamiento y unidades vectoriales disponibles en la arquitectura, la cual se abarca con mayor detalle en la Secci\'on \ref{ch:marco_xeonphi}. 
Para lograr una mayor optimizaci\'on del algoritmo, se se utilizan datos alineados en memoria gracias a las primitivas de procesamiento de im\'agenes y se\~nales \textit{Integrated Performance Primitives} (IPP), especialmente dise\~nada para permitir la vectorizaci\'on de sus rutinas de procesamiento de im\'agenes \cite{IntelCorporation2017}.       Sumado a lo anterior, se utiliza OpenMP para la paralelizaci\'on a nivel de tareas de los algoritmos de filtrado. 

Este trabajo forma parte del proyecto de investigaci\'on llamado ``Análisis funcional genómico de células cancerosas por RNA de interferencia para la identificación de redes de regulación asociadas a proliferación y muerte en respuesta a quimioterapia genotóxica'', financiado por el Fondo Especial para la Educaci\'on Superior (FEES) del Consejo Nacional de Rectores (CONARE) y con participaci\'on de investigadores del TEC, UCR y CNCA. 


\section{Objetivos y estructura del documento}

\index{objetivos}

Este trabajo tiene como objetivo la implementaci\'on de una optimizaci\'on computacional del filtro DNLM especializada para la arquitectura Xeon Phi Knights Landing, con el objetivo de acelerar el tiempo de procesamiento de las im\'agenes. La paralelizaci\'on se realiza en dos niveles: paralelismo a nivel de tareas y paralelismo a nivel del datos. El paralelismo a nivel de tareas se utiliza en la descomposici\'on del procesamiento de la imagen en subtareas independientes para secciones de la imagen, con cierto grado de granularidad. Esto tiene como objetivo explotar caracter\'isticas propias de la arquitectura como la gran cantidad de hilos de procesamiento, la localidad de cach\'e y el uso de memoria de alto ancho de banda. El paralelismo a nivel de datos se realiza mediante la vectorizaci\'on de operaciones. Finalmente se pretende evaluar la soluci\'on propuesta por medio de una comparaci\'on entre dos optimizaciones y la versi\'on original del filtro DNLM.


\index{estructura}
La presente tesis est\'a organizada de la siguiente manera: el Cap\'itulo \ref{chp:intro} corresponde a la introducci\'on, el contexto en el que se desarrolla este trabajo y los objetivos. Seguidamente en el Cap\'itulo \ref{ch:marco} se detalla el marco te\'orico necesario para el desarrollo de la tesis y en el Cap\'itulo \ref{ch:solucion} se presenta la soluci\'on. El Cap\'itulo \ref{ch:res} corresponde al desarrollo del experimento y finalmente, se presentan las conclusiones y el trabajo futuro en el Cap\'itulo \ref{ch:concl}. 
