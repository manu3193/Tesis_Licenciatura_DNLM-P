%% ---------------------------------------------------------------------------
%% intro.tex
%%
%% Introduction
%%
%% $Id: intro.tex 1477 2010-07-28 21:34:43Z palvarado $
%% ---------------------------------------------------------------------------

\chapter{Introducción}
\label{chp:intro}

Los algoritmos de procesamiento de im\'agenes son utilizados en campos como la medicina, microbiología e incluso deportes \cite{Aggarwal2011,	Ekin2003, Fils_BfilCells_2008}. El mejoramiento de las im\'agenes por medio de algoritmos de procesamiento permiten obtener el realce de características o información relevante y la atenuación de información no deseada en una imagen. 

Sumado a lo anterior, la eliminación de ruido en las imágenes es un problema ampliamente estudiado en la literatura, con numerosas técnicas propuestas \cite{edgpreservefilter}. Se ha demostrado que la presencia de ruido en las imágenes reduce el rendimiento de algoritmos de procesamiento de imágenes como segmentación, rastreo de objetos, clasificación y la extracción de características \cite{BF2014,IMPROVESEGMENTATIONBF,CONCAPAN2016}. Esto hace que sea necesaria la integración de algoritmos de eliminación de ruido con técnicas de realce de información, como etapa de preprocesamiento para mejorar el rendimiento de las etapas posteriores de procesamiento.  

En la literatura se encuentran aplicaciones que requieren el preprocesamiento de los datos, como es el caso del análisis automatizado de videos de actividad celular \cite{saenz2015deceived}. En ese trabajo los autores proponen un sistema automatizado de segmentación y rastreo de células, con el objetivo de asistir a investigadores del cáncer y campos afines a comprender el comportamiento de grupos de células afectadas por la enfermedad \cite{saenz2015deceived}. La primera etapa de el sistema de rastreo de células presentado por los autores, corresponde al preprocesamiento de las imágenes de entrada. En esta etapa se usa un filtro de promedio ponderado para la eliminación de ruido, como lo son el filtro bilateral y el filtro \engl{Non-Local Means} (promediado no local). Este filtro se integra con un método \engl{Unsharp Masking} (máscara de enfoque) con el objetivo de mejorar los bordes y el contraste en la imagen, como se propone en \cite{calderon2015dewaff}. 

Además, en \cite{CNN_DNLM} se propone el uso de una etapa de preprocesado para algoritmos de procesamiento de imágenes basados en redes convolucionales, ya que muestra un impacto positivo en el rendimiento general del modelo. Los algoritmos de preprocesamiento de imágenes basados en modelos de redes convolucionales generan extractores de características a partir de los datos de entrenamiento, a diferencia de los enfoques convencionales de procesamiento de imágenes. Lo anterior hace pensar que los modelos basados en redes convolucionales son más robustos ante la presencia de ruido en imágenes. Sin embargo, los resultados obtenidos en \cite{CNN_DNLM} sugieren que los métodos basados en redes convolucionales también se ven afectados por el ruido en los datos. Esto hace que sea necesario explorar etapas de preprocesamiento de los datos para eliminar el ruido y además realzar información relevante.

La mejora en el rendimiento de métodos de reconocimiento de patrones basados en imágenes, utilizando algoritmos de preprocesamiento efectivos y complejos, generalmente implica un aumento de recursos computacionales necesarios. Lo anterior conduce al desarrollo de algoritmos de preprocesamiento cada vez más eficientes que logren mitigar el aumento en la complejidad computacional en las tareas comunes de procesamiento de imágenes. 


El filtro \engl{Non-Local Means} (NLM) propuesto en \cite{buades2005non} ha demostrado resultados destacables en términos relación se\~nal-ruido y poca degradación o pérdida de detalles como bordes, en comparación con otros filtros como el de mediana y el bilateral \cite{CONCAPAN2016}. Esto es debido a que su enfoque se basa en la similitud entre los vecindarios de los pixeles de la imagen para asignar el peso correspondiente a la contribución de cada pixel vecino en el ponderamiento del valor del pixel procesado. 

Uno de los principales inconvenientes del filtro NLM es su complejidad computacional: para una imagen de entrada en escala de grises de $N$ pixeles, con un tamaño de ventana deslizante de $S$ pixeles y un tamaño de vecindario de $P$ pixeles, la complejidad computacional está dada por $\mathcal{O}(N\cdot~S\cdot~P)$, tardando hasta $32$ s en el filtrado de una imagen de $1024 \times 1024$ pixeles \cite{Zhu2016}. Esto hace que el filtro DNLM sin optimizar sea poco práctico para los investigadores de áreas como la microbiología, ya que frecuentemente necesitan analizar videos de actividad celular compuestos por cientos de miles de imágenes, implicando múltiples días de procesamiento. 

Existen mejoras desarrolladas a partir del algoritmo NLM como el propuesto en \cite{calderon2015dewaff} llamado filtro DNLM \engl{Deceived Non-Local Means} (ponderado no local enga\~nado). Presenta una combinación del método \engl{Unsharp Masking} (USM) con el filtro NLM por medio del desacoplamiento de la imagen utilizada en el pesado y la imagen usada en el filtrado. Esta modificación utiliza la imagen de entrada para el cálculo de los pesos y la imagen producto del método USM para realizar el filtrado. Con esto se reducen los artefactos no deseados en las imágenes (efecto de anillo) generados por el enfoque convencional, es decir, al aplicar en una primera etapa el método USM y posteriormente el filtro NLM \cite{calderon2015dewaff}.  


Una forma de reducir la complejidad computacional del filtro es mediante el uso de optimizaciones o aproximaciones del algoritmo. En este trabajo se incluye el estudio de optimizaciones computacionales exactas del algoritmo y no aproximaciones. Esto es debido a que algunas optimizaciones logran reducir en efecto la complejidad computacional del algoritmo, sin embargo en este trabajo se concentra en optimizaciones computacionales exactas, es decir, con la misma respuesta que la implementación original del filtro DNLM. 

Sumado al análisis de las optimizaciones algorítmicas del filtro DNLM para disminuir su costo computacional, se busca alcanzar el mayor aprovechamiento del \engl{hardware} por medio de la vectorización y paralelización del algoritmo. Para esto se propone una estrategia de paralelización para computación de alto rendimiento enfocada en la arquitectura \engl{Xeon Phi Knigths Landing} (KNL) disponible en las instalaciones del Centro Nacional de Alta Tecnología, como parte del clúster de alto rendimiento Kabré del Colaboratorio Nacional de Computación Avanzada (CNCA).

La estrategia de paralelización propuesta en este trabajo se enfoca en la paralelización del algoritmo a nivel intra-nodo, para el aprovechamiento total de los núcleos de procesamiento y unidades vectoriales disponibles en la arquitectura, la cual se abarca con mayor detalle en la Sección \ref{ch:marco_xeonphi}. 
Para lograr una mayor aceleración del algoritmo, se utilizan datos alineados en memoria gracias a las primitivas de procesamiento de imágenes y se\~nales \engl{Integrated Performance Primitives} (IPP), especialmente dise\~nadas para permitir la vectorización de sus rutinas de procesamiento de imágenes \cite{IntelCorporation2017}. Sumado a lo anterior, se hace el uso de OpenMP para la paralelización a nivel de tareas de los algoritmos de filtrado. 

Este trabajo forma parte del proyecto de investigación llamado ``Análisis funcional genómico de células cancerosas por RNA de interferencia para la identificación de redes de regulación asociadas a proliferación y muerte en respuesta a quimioterapia genotóxica'', financiado por el Fondo Especial para la Educación Superior (FEES) del Consejo Nacional de Rectores (CONARE) y con participación de investigadores del TEC, UCR y CNCA. 


\section{Objetivos y estructura del documento}

\index{objetivos}

Este trabajo tiene como objetivo proponer una optimización computacional y paralelización del filtro DNLM  para la plataforma \engl{Xeon Phi Knights Landing}, con el objetivo de acelerar el tiempo de procesamiento de las imágenes. La paralelización se realiza en dos niveles: paralelismo a nivel de tareas y paralelismo a nivel del datos. El paralelismo a nivel de tareas se utiliza en la descomposición del procesamiento de la imagen en subtareas independientes para secciones de la imagen, con cierto grado de granularidad. Esto tiene como objetivo explotar características propias de la arquitectura como la gran cantidad de hilos de procesamiento, la localidad de caché y el uso de memoria de alto ancho de banda. El paralelismo a nivel de datos se realiza mediante la vectorización de operaciones. Finalmente se pretende evaluar la solución propuesta por medio de una comparación entre dos optimizaciones y la versión original del filtro DNLM.


\index{estructura}
La presente tesis está organizada de la siguiente manera: en el Capítulo \ref{ch:marco} se detalla el marco teórico necesario para el desarrollo de la tesis y en el Capítulo \ref{ch:solucion} se presenta la propuesta de optimización. El Capítulo \ref{ch:res} presenta los resultados experimentales y finalmente, se presentan las conclusiones y el trabajo futuro en el Capítulo \ref{ch:concl}. 
